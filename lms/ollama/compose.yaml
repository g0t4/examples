services:
  ollama:
    image: ollama/ollama
    ports:
      - "11434:11434" # appears to only be ipv6 per netstat 
    volumes:
      - ollama:/root/.ollama
    # command: ollama run llama3 ?
# TODO amd:
#   docker run -d --device /dev/kfd --device /dev/dri -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama:rocm
# or NVIDIA: https://hub.docker.com/r/ollama/ollama

volumes:
  ollama:

# docker compose exec ollama bash
#   ollama pull llama3
#   TODO llama3 model was super slow, TODO try others...

# RUNS AWESOME on my mac, forget using docker for now